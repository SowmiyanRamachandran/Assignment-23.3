1.Explain Hive Architecture in Brief ?

-An essential tool in the Hadoop ecosystem that provides an SQL (Structured Query Language) dialect (called as Hive Query Language) for querying data stored in the Hadoop Distributed Filesystem (HDFS).
-Hive is most suited for data warehouse applications, where relatively static data is analyzed, fast response times are not required, and when the data is not changing rapidly.

HIVE ARCHITECTURE :

USER INTERFACE 
-The user interface for users to submit queries and other operations to the system.
 As of 2011 the system had a command line interface and a web based GUI was being developed.
 For example, command line interface and a web based GUI.

Driver:
- The component which receives the queries.
- This component implements the notion of session handles and provides execute and fetch APIs modelled on JDBC/ODBC interfaces.

Compiler:
• The component that parses the query, does semantic analysis on the different query blocks and query expressions and eventually generates an execution plan with the help of the table and partition metadata looked up from the metastore. Metastore
• The component that stores all the structure information of the various tables and partitions in the warehouse including column and column type information, the serializers and deserializers necessary to read and write data and the corresponding HDFS files where the data is stored. Execution Engine
• The component which executes the execution plan created by the compiler. The plan is a DAG of stages. The execution engine manages the dependencies between these different stages of the plan and executes these stages on the appropriate system components.

As show in hive architecture
Step 1-The UI calls the execute interface to the Driver.
Step 2-The Driver creates a session handle for the query and sends the query to the compiler to generate an execution plan.
Step 3and 4-The compiler needs the metadata so send a request for getMetaData and receives the sendMetaData request from MetaStore.
Step 5-This metadata is used to typecheck the expressions in the query tree as well as to prune partitions based on query predicates.
The plan generated by the compiler is a DAG of stages with each stage being either a map/reduce job, a metadata operation or an operation on HDFS.
Step 6 The execution engine submits these stages to appropriate components.
Once the output is generated, it is written to a temporary HDFS file though the serializer.
For DML operations the final temporary file is moved to the table’s location Step 7, 8 & 9.

2.Explain Hive Components in Brief ?

Hive Components are : 

Execution Engine: 
- MapReduce is the default execution engine for Hive because Hive was written originally to use MapReduce.
- The execution engine is controlled by the hive.execution.engine property, which defaults to MR (for MapReduce). 
- Hive can also be run on other execution engines like Tez, spark.

Metastore :
- The Hive metastore service stores the metadata for Hive tables and partitions in a relational database, and provides clients (including Hive) access to this information via the metastore service API.
- The metastore is the central repository of Hive metadata.
- The metastore service runs in the same JVM as the Hive service and contains an embedded Derby * database instance.
- However, only one embedded Derby database can access the database files on disk at any one time, which means we can have only one Hive session open at a time.

Driver :
- Manages lifecycle of a HiveQL statement as it moves through Hive.
- It also maintains a session handle and session statistics.

Query Compiler :

Compiles HiveQL into a directed acryclic graph of MapReduce tasks.

Extensibility Interfaces:
Is like the Command Line Interface (CLI), the web UI and JDBC/ODBC driver.
It includes UDF(UserDefined Function) and UDAF(User Defined Aggregate Function) interfaces that enable users to define their own custom functions.

Hive Server: Provides a thrift interface and a JDBC/ODBC server and a way of integrating Hive with other applications.
